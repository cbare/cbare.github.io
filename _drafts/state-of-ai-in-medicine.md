---
layout: post
title:  "The State of AI in Healthcare"
category: Health-tech and Biotechnology
tags: ai healthcare
---

## Adoption of AI in Healthcare

Healthcare workflows are complex. In a simple case, a patient might visit a primary care doc, a lab for a blood draw or imaging, specialist clinicians make a diagnosis and design a treatment plan, and pharmicist to dispense a medication. Successful AI models have to fit into that workflow.

You can put applications on two axes: easy to hard and low to high risk. The things done first will be easy and low risk.

For examples, clinics have "suggestion boxes" to spot lapses in infection control protocols. LLMs are good at sifting through the submissions to find themes.

How do we monitor AI algorithms and devices in the wild? If performance drops will that be spotted?

## Data

To get to personalized medicine, we need to share data in order to get a comprehensive view.

- privacy
- security
- data ownership and usage rights
- incentives

Liability and differences in payors distort what tests get done, for example what tests get done.

### Data quality

Due to incentives, much of the medical data that exists is focused on billing. 

## Bias & inequity

Consider:

- data
- algorithm
- action taken

Bias and equity issues can arise in the training data, the algorithm itself, or in the action taken as a result of the output of the model.

## Resources

A panel discussion at Stanford [The State of AI in Healthcare and Medicine][1] featuring [Nigam H. Shah][2],chief data scientist at Stanford Healthcare and research and co-director at the Center for AI in Medicine & Imaging.

[1]: https://www.youtube.com/watch?v=D7O3wn3TjNU
[2]: https://shahlab.stanford.edu/
