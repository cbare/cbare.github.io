---
layout: post
title:  "Alignment"
category: AI, Machine Learning, Deep Learning
---

[Discovering Language Model Behaviors with Model-Written Evaluations][1]
[Eight Things to Know about Large Language Models][2]
[Anthropic's Responsible Scaling Policy][3]
[Sleeper Agents: Training Deceptive LLMs That Persist Through Safety Training][4]
[Evan Hubinger (Anthropic)â€”Deception, Sleeper Agents, Responsible Scaling][5]
[Universal and Transferable Adversarial Attacks on Aligned Language Models][6]
[Jailbroken: How Does LLM Safety Training Fail?][7]

[1]: https://arxiv.org/pdf/2212.09251
[2]: https://arxiv.org/abs/2307.15043
[3]: https://www.anthropic.com/news/anthropics-responsible-scaling-policy
[4]: https://arxiv.org/pdf/2401.05566
[5]: https://www.youtube.com/watch?v=S7o2Rb37dV8
[6]: https://arxiv.org/abs/2307.15043
[7]: https://arxiv.org/pdf/2307.02483
