# The New Learning Loop

build a [learning loop][13] around the system

## Low consequence to model failure

What you're aiming for is that when the model failes, the user clicks a red X and does what they would have done previously without the model.

## Increasing the parts of the system that can be learned

Over time, the parts of the system that previously had to be done by humans can increasingly be learned. In classic machine learning, feature extraction was mostly up to humans. Deep learning models automate feature extraction. [RLHF][10] and reward models allow the objective function to be learned.

[Large Language Models (in 2023), Hyung Won Chung][12]

Textio CEO Kieran Snyder


[10]: https://huggingface.co/blog/rlhf
[11]: https://huyenchip.com/2023/05/02/rlhf.html
[12]: https://www.youtube.com/watch?v=dbo3kNKPaUA
[13]: https://medium.com/textio/https-medium-com-kieransnyder-the-learning-loop-revolution-f1d0e65b23
