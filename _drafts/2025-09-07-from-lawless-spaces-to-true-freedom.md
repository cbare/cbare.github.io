# From lawless spaces to true freedom

Kanjun Qiu and Matt of Imbue


Four categories of AI risk:

1. Enabling bad actors: LLMs themselves included in potential bad actors.
2. Transferring power from labor to capital
3. Resistability: How well can you resist laws and institutions that don't serve you? Legibility is important. How do you resist or influence systems that are illegible?
4. 


Loss of economic power leads to loss of political power. The world comes to look like the natural resource heavy countries, like Russia or Saudi Arabia, where wealth comes out of the ground and there's little incentive to treat the people well.

Spiritual or psychic damage that results from diminishing people's own perception of what they are capable. Like people who graduate during a recession have lower wages for the rest of their lives. Disempowering people might result in the same kind of psychic damage.

We adopt technologies for its benefits and then we suffer its consequences. After we adopt a technology, it changes how we do things, it changes us. You can't exit a technology. It's hard to resist.

Do LLMs change the way we perceive the world? Do they change it in a manipulative way? Technology companies make lots of money through surveiling users.

Technology is something of a lawless space, which can be liberating and lucrative. Digital spaces are not particularly visible. We don't see what's logged, recorded and sold, or what's done with our data. Because we don't see it, there's not a push to regulate.

There's a ton of good tinkering to be done with LLMs.

positive and negative freedoms



As technologists, the opportunity we have is to create technology that deeply respects freedom, deep enablement and deep protection.
